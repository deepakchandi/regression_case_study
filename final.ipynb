{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.metrics import make_scorer, mean_squared_log_error, mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import src.model as m\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalesID</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>MachineID</th>\n",
       "      <th>ModelID</th>\n",
       "      <th>datasource</th>\n",
       "      <th>auctioneerID</th>\n",
       "      <th>YearMade</th>\n",
       "      <th>MachineHoursCurrentMeter</th>\n",
       "      <th>UsageBand</th>\n",
       "      <th>saledate</th>\n",
       "      <th>...</th>\n",
       "      <th>Undercarriage_Pad_Width</th>\n",
       "      <th>Stick_Length</th>\n",
       "      <th>Thumb</th>\n",
       "      <th>Pattern_Changer</th>\n",
       "      <th>Grouser_Type</th>\n",
       "      <th>Backhoe_Mounting</th>\n",
       "      <th>Blade_Type</th>\n",
       "      <th>Travel_Controls</th>\n",
       "      <th>Differential_Type</th>\n",
       "      <th>Steering_Controls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1139246</td>\n",
       "      <td>66000</td>\n",
       "      <td>999089</td>\n",
       "      <td>3157</td>\n",
       "      <td>121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>11/16/2006 0:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Conventional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1139248</td>\n",
       "      <td>57000</td>\n",
       "      <td>117657</td>\n",
       "      <td>77</td>\n",
       "      <td>121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1996</td>\n",
       "      <td>4640.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>3/26/2004 0:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Conventional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139249</td>\n",
       "      <td>10000</td>\n",
       "      <td>434808</td>\n",
       "      <td>7009</td>\n",
       "      <td>121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>2838.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2/26/2004 0:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1139251</td>\n",
       "      <td>38500</td>\n",
       "      <td>1026470</td>\n",
       "      <td>332</td>\n",
       "      <td>121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>3486.0</td>\n",
       "      <td>High</td>\n",
       "      <td>5/19/2011 0:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1139253</td>\n",
       "      <td>11000</td>\n",
       "      <td>1057373</td>\n",
       "      <td>17311</td>\n",
       "      <td>121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>722.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>7/23/2009 0:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalesID  SalePrice  MachineID  ModelID  datasource  auctioneerID  YearMade  \\\n",
       "0  1139246      66000     999089     3157         121           3.0      2004   \n",
       "1  1139248      57000     117657       77         121           3.0      1996   \n",
       "2  1139249      10000     434808     7009         121           3.0      2001   \n",
       "3  1139251      38500    1026470      332         121           3.0      2001   \n",
       "4  1139253      11000    1057373    17311         121           3.0      2007   \n",
       "\n",
       "   MachineHoursCurrentMeter UsageBand         saledate        ...         \\\n",
       "0                      68.0       Low  11/16/2006 0:00        ...          \n",
       "1                    4640.0       Low   3/26/2004 0:00        ...          \n",
       "2                    2838.0      High   2/26/2004 0:00        ...          \n",
       "3                    3486.0      High   5/19/2011 0:00        ...          \n",
       "4                     722.0    Medium   7/23/2009 0:00        ...          \n",
       "\n",
       "  Undercarriage_Pad_Width Stick_Length Thumb Pattern_Changer Grouser_Type  \\\n",
       "0                     NaN          NaN   NaN             NaN          NaN   \n",
       "1                     NaN          NaN   NaN             NaN          NaN   \n",
       "2                     NaN          NaN   NaN             NaN          NaN   \n",
       "3                     NaN          NaN   NaN             NaN          NaN   \n",
       "4                     NaN          NaN   NaN             NaN          NaN   \n",
       "\n",
       "  Backhoe_Mounting Blade_Type Travel_Controls Differential_Type  \\\n",
       "0              NaN        NaN             NaN          Standard   \n",
       "1              NaN        NaN             NaN          Standard   \n",
       "2              NaN        NaN             NaN               NaN   \n",
       "3              NaN        NaN             NaN               NaN   \n",
       "4              NaN        NaN             NaN               NaN   \n",
       "\n",
       "  Steering_Controls  \n",
       "0      Conventional  \n",
       "1      Conventional  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/Train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Pipeline\n",
    "I set this cell up to allow easy selection of features while performing the development of my modeling pipeline, and for tuning the various models that I wanted to train. Just select the features to be used by uncommenting them, making sure to include the `SalesID` as this gets mapped back to predictions for later testing.\n",
    "\n",
    "Categorical features will automatically be handled by pivoting into dummy variables using one-hot formatting, and `NaN` values will be inferred from the median of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "'SalesID' ,      # Always included as key for predictions\n",
    "# 'MachineID' ,\n",
    "'ModelID' ,\n",
    "# 'datasource' ,\n",
    "# 'auctioneerID' ,\n",
    "'YearMade' ,\n",
    "# 'MachineHoursCurrentMeter',\n",
    "# 'UsageBand',\n",
    "# 'saledate',    # BE CAREFUL\n",
    "# 'fiModelDesc',\n",
    "# 'fiBaseModel',\n",
    "# 'fiSecondaryDesc',\n",
    "# 'fiModelSeries',\n",
    "# 'fiModelDescriptor',\n",
    "'ProductSize',\n",
    "# 'fiProductClassDesc',\n",
    "# 'state',\n",
    "'ProductGroup',\n",
    "# 'ProductGroupDesc',\n",
    "# 'Drive_System',\n",
    "'Enclosure',\n",
    "# 'Forks',\n",
    "# 'Pad_Type',\n",
    "# 'Ride_Control',\n",
    "# 'Stick',\n",
    "# 'Transmission',\n",
    "# 'Turbocharged',\n",
    "# 'Blade_Extension',\n",
    "# 'Blade_Width',\n",
    "'Enclosure_Type',\n",
    "# 'Engine_Horsepower',\n",
    "'Hydraulics',\n",
    "# 'Pushblock',\n",
    "# 'Ripper',\n",
    "# 'Scarifier',\n",
    "# 'Tip_Control',\n",
    "'Tire_Size',\n",
    "# 'Coupler',\n",
    "# 'Coupler_System',\n",
    "# 'Grouser_Tracks',\n",
    "# 'Hydraulics_Flow',\n",
    "# 'Track_Type',\n",
    "# 'Undercarriage_Pad_Width',\n",
    "# 'Stick_Length',\n",
    "# 'Thumb',\n",
    "# 'Pattern_Changer',\n",
    "# 'Grouser_Type',\n",
    "# 'Backhoe_Mounting',\n",
    "# 'Blade_Type',\n",
    "# 'Travel_Controls',\n",
    "# 'Differential_Type',\n",
    "# 'Steering_Controls'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `model.py` for `clean_features` function details. This contains the function call to handle categorical variables, and perform any other transformations on data required before fitting and predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess features and target\n",
    "X_df, y_df = m.clean_features(df, features, 'SalePrice')\n",
    "\n",
    "# Save list of dummy variables and numeric features\n",
    "trained_features = list(X_df.columns)\n",
    "\n",
    "# Separate `SalesID` for mapping back to predictions\n",
    "X_sid = X_df.pop('SalesID')\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `sklearn` Pipeline to orchestrate feature scaling, model fitting, and model predictions. The Pipeline scoring method isn't used, and honestly I don't know what scoring function it's using. If this could be set to use the Root Mean Squared Log Error, it would save some code.\n",
    "\n",
    "The target values, `y` are logged before fitting the model, then unlogged after predictions are made to better fit the model to the loss function. Again, this might not be necessary if the correct loss function could be specified as part of the Linear Regression model.\n",
    "\n",
    "Predictions may be less than zero. Both because the scenario and the loss function prevent values less than zero, these are set to the mean of the target values from the training data. The result is a lower error score than setting these values to zero, however in a practical setting we'd likely set them to zero instead of providing a potentially misleading valuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 15639.599868884077\n",
      "RMSLE: 0.4261928140193535\n"
     ]
    }
   ],
   "source": [
    "# Train model (log target)\n",
    "pipeline = Pipeline([('scalar', StandardScaler()), ('linear', LinearRegression())])\n",
    "pipeline.fit(X_train, np.log(y_train))\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Floor predictions at mean (unlog target)\n",
    "y_pred[y_pred < 0] = y_train.mean()\n",
    "y_pred = np.exp(y_pred)\n",
    "\n",
    "# Scoring\n",
    "rmse_score = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "rmsle_score = np.sqrt(mean_squared_log_error(y_pred, y_test))\n",
    "\n",
    "# print(X_train.columns)\n",
    "print('RMSE: {}'.format(rmse_score))\n",
    "print('RMSLE: {}'.format(rmsle_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination with Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempted to use Recursive Feature Elimination to potentially identify the most significant features for use in the model. This could also have been done using `statsmodels` by inspecting the p-values of each feature, but I decided to try and automated route.\n",
    "\n",
    "The results were more challenging to interpret, and will also be more challenging to include in the regression model pipeline because the features returned are often dummy variables that don't appear as columns in the original data set, but as column values. These could be saved and used to further reduce the features included, which will be my next step in improving this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing features\n",
    "X_df, y_df = m.clean_features(df, features, 'SalePrice')\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This case required me to define scoring functions up front that the RFE could then use to evaluate the performance of each model. These scoring functions are different from the metric functions that can be used for similar purpose in that they accept the metric function as the argument. I'm unclear on whether there are additional differences.\n",
    "\n",
    "Note that this method takes a significantly greater time to process than just running a Ridge or Linear Regression because it is infact running several models and choosing the best. It's therefore sensitive to the inclusion of additional features, especially dummy features, and definitely dummy features with many unique values.\n",
    "\n",
    "The result is both a list of features identified, and a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['SalesID', 'ModelID', 'YearMade', 'compact', 'large', 'large / medium',\n",
      "       'medium', 'mini', 'high profile', 'low profile', 'erops', 'erops ac',\n",
      "       'erops w ac', 'no rops', 'none or unspecified_x', '10 inch', '10\"',\n",
      "       '13\"', '14\"', '15.5', '15.5\"', '17.5', '17.5\"', '20.5', '20.5\"',\n",
      "       '23.1\"', '23.5', '23.5\"', '26.5', '29.5', '7.0\"', 'bl', 'mg', 'ssl',\n",
      "       'tex', 'ttt', '2 valve', '3 valve', '4 valve', 'auxiliary',\n",
      "       'base + 1 function', 'base + 2 function', 'base + 3 function',\n",
      "       'base + 4 function', 'base + 5 function', 'base + 6 function',\n",
      "       'none or unspecified_y'],\n",
      "      dtype='object')\n",
      "\n",
      "RMSE: 15358.010189884355\n",
      "RMSLE: 0.42154190253203383\n"
     ]
    }
   ],
   "source": [
    "# Scoring functions\n",
    "msle_func = make_scorer(mean_squared_log_error)\n",
    "mse_func = make_scorer(mean_squared_error)\n",
    "\n",
    "# Recursive Feature Elimination\n",
    "estimator = LinearRegression()\n",
    "selector = RFECV(estimator, cv=10)\n",
    "# selector = RFE(estimator, n_features_to_select=20)\n",
    "selector = selector.fit(X_train, np.log(y_train))\n",
    "y_pred = selector.predict(X_test)\n",
    "\n",
    "# Floor predictions at zero\n",
    "y_pred[y_pred < 0] = y_train.mean()\n",
    "y_pred = np.exp(y_pred)\n",
    "\n",
    "# Scoring\n",
    "rmse_score = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "rmsle_score = np.sqrt(mean_squared_log_error(y_pred, y_test))\n",
    "\n",
    "print('Selected features: {}'.format(X_train.columns[selector.support_]))\n",
    "print('\\nRMSE: {}'.format(rmse_score))\n",
    "print('RMSLE: {}'.format(rmsle_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch & Ridge Regression\n",
    "#### GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used a grid search algorithm here to identify the ideal alpha value when performing a Ridge Regression using the same features. A ridge is ideal for situations where the scale of a feature is causing more drastic model changes than another feature of a smaller scale. I didn't anticipate significant performs changes here, but wanted to test it to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'alpha': 1}\n",
      "Best Score: 0.6285853750279499\n",
      "\n",
      "RMSE: 15357.779638176247\n",
      "RMSLE: 0.4215332407756455\n"
     ]
    }
   ],
   "source": [
    "# Set the range of hyper-parameters to search\n",
    "params = {'alpha': [1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "\n",
    "# Perform grid search\n",
    "ridge = Ridge()\n",
    "g = GridSearchCV(ridge, params, cv=10)\n",
    "g.fit(X_train, np.log(y_train))\n",
    "\n",
    "# Predictions\n",
    "g_pred = g.predict(X_test)\n",
    "\n",
    "# Floor predictions at zero\n",
    "g_pred[g_pred < 0] = y_train.mean()\n",
    "g_pred = np.exp(g_pred)\n",
    "\n",
    "# Scoring\n",
    "rmse_score = np.sqrt(mean_squared_error(g_pred, y_test))\n",
    "rmsle_score = np.sqrt(mean_squared_log_error(g_pred, y_test))\n",
    "\n",
    "print('Best Params: {}'.format(g.best_params_))\n",
    "print('Best Score: {}'.format(g.best_score_))\n",
    "print('\\nRMSE: {}'.format(rmse_score))\n",
    "print('RMSLE: {}'.format(rmsle_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression\n",
    "The best parameters identified by the grid search are then used for a Ridge Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 15357.779638176247\n",
      "RMSLE: 0.4215332407756455\n"
     ]
    }
   ],
   "source": [
    "# Train ridge regressor using optimal alpha value\n",
    "ridge = Ridge(alpha=1)\n",
    "ridge.fit(X_train, np.log(y_train))\n",
    "ridge_pred = ridge.predict(X_test)\n",
    "\n",
    "# Floor predictions at mean\n",
    "ridge_pred[ridge_pred < 0] = y_train.mean()\n",
    "ridge_pred = np.exp(ridge_pred)\n",
    "\n",
    "# Scoring\n",
    "rmse_score = np.sqrt(mean_squared_error(ridge_pred, y_test))\n",
    "rmsle_score = np.sqrt(mean_squared_log_error(ridge_pred, y_test))\n",
    "\n",
    "# print(X_train.columns)\n",
    "print('RMSE: {}'.format(rmse_score))\n",
    "print('RMSLE: {}'.format(rmsle_score))\n",
    "# ridge.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for science, I tested a LASSO regression to try and perform feature elimination similarly to how the Recursive Feature Elimination was used.\n",
    "\n",
    "While the results of this model weren't as accurate as those of the regular Linear Regression or Ridge Regression, I was able to identify one feature which could be eliminated. The `auctioneerID`. While in my initial development of this model, this feature did contribute to a more accurate score, as I made refinements and changes it became less and less relevant. Using LASSO as a double check allowed me to identify this by inspecting the resulting coefficients. \n",
    "\n",
    "This doesn't however appear to be a universal truth, as many of the coefficients now returned by the LASSO show zero values, when in truth removing these features causes a noticable and consistent drop in model performance. I plan to continue researching this and RFE for feature selection in the future, but at the very least found it somewhat useful for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 23517.281710535666\n",
      "RMSLE: 0.6738527287081943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-8.07763562e-09, -1.53859786e-05,  9.20094763e-03, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "lasso = LassoCV()\n",
    "lasso.fit(X_train, np.log(y_train))\n",
    "lasso_pred = lasso.predict(X_test)\n",
    "\n",
    "# Floor predictions at mean\n",
    "lasso_pred[lasso_pred < 0] = y_train.mean()\n",
    "lasso_pred = np.exp(lasso_pred)\n",
    "\n",
    "# Scoring\n",
    "rmse_score = np.sqrt(mean_squared_error(lasso_pred, y_test))\n",
    "rmsle_score = np.sqrt(mean_squared_log_error(lasso_pred, y_test))\n",
    "\n",
    "# print(X_train.columns)\n",
    "print('RMSE: {}'.format(rmse_score))\n",
    "print('RMSLE: {}'.format(rmsle_score))\n",
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce Test Predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally! After all the testing and tuning is complete. I've selected my features, selected my preferred model and am ready to test it against my held out test data. In an effort to avoid overfitting to this test data, I tried to limit as many interactions with it as possible as tempting as it may be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "X = m.clean_features(test_df, features, target=None, fill=trained_features)\n",
    "sid = X.pop('SalesID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing my predictions using the trained model, it was necessary to merge the `SalesID` field back in so that the final testing script could verify the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pipeline.predict(X)\n",
    "# test_pred = ridge.predict(X)\n",
    "\n",
    "# Floor predictions at mean\n",
    "test_pred[test_pred < 0] = y_train.mean()\n",
    "test_pred = np.exp(test_pred)\n",
    "\n",
    "# Merge SalesID field into final predictions\n",
    "results = pd.concat([pd.Series(sid), pd.Series(test_pred)], axis=1)\n",
    "results.columns = ['SalesID', 'SalePrice']\n",
    "\n",
    "# Save to file\n",
    "results.to_csv('./data/test_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check test score using `score_model.py`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43302545309068696\n"
     ]
    }
   ],
   "source": [
    "!python score_model.py ./data/test_predictions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
